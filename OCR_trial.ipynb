{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a9d6aac-c6d7-43c9-b1bc-c0ef8b87e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import PIL.Image\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7410ff7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOCR Engine Modes:\\n\\n0   Legacy Engine Only.\\n1   Neural Nets LSTM Engine Only.\\n2   Legacy + LSTM Engines.\\n3   Default, based on what is available.\\n\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Page Segmentation Modes:\n",
    "\n",
    "  0    Orientation and script detection (OSD) only. (This option returns these values:\n",
    "  First the orientation of the page in degrees and second,confidence numbers of the script. Example:\n",
    "  Page number: 0\n",
    "  Orientation in degrees: 0\n",
    "  Rotate: 0\n",
    "  Orientation confidence: 11.34\n",
    "  Script: Latin\n",
    "  Script confidence: 8.10  )\n",
    "\n",
    "\n",
    "  1    Automatic page segmentation with OSD.\n",
    "\n",
    "  2    Automatic page segmentation, but no OSD, or OCR. (not implemented)\n",
    "\n",
    "  3    Fully automatic page segmentation, but no OSD. (Default)\n",
    "  (Automatically attempt to segment the text, treating it as a proper “page” of text with multiple words,\n",
    "   multiple lines, multiple paragraphs, etc.\n",
    "   After segmentation, Tesseract will OCR the text and return it to you\n",
    "   However, it’s important to note that Tesseract will not perform any orientation/script detection. \n",
    "   To gather that information, you will need to run tesseract twice:\n",
    "\n",
    "   Once with the --psm 0 mode to gather OSD information\n",
    "   And then again with --psm 3 to OCR the actual text)\n",
    "\n",
    "\n",
    "  4    Assume a single column of text of variable sizes.\n",
    "  (A good example of using --psm 4 is when you need to OCR column data and require text to be concatenated row-wise \n",
    "  (e.g., the data you would find in a spreadsheet, table, or receipt).)\n",
    "\n",
    "  5    Assume a single uniform block of vertically aligned text.\n",
    "\n",
    "  6    Assume a single uniform block of text.\n",
    "(Pages in books tend to use a single, consistent font throughout the entirety of the book. Similarly, \n",
    "these books follow a simplistic page structure, which is easy for Tesseract to parse and understand.\n",
    "The keyword here is uniform text, meaning that the text is a single font face without any variation.)\n",
    "\n",
    "  7    Treat the image as a single text line.\n",
    "  8    Treat the image as a single word.\n",
    "  9    Treat the image as a single word in a circle.\n",
    " 10    Treat the image as a single character.\n",
    " 11    Sparse text. Find as much text as possible in no particular order.\n",
    " 12    Sparse text with OSD.\n",
    " 13    Raw line. Treat the image as a single text line,\n",
    "       bypassing hacks that are Tesseract-specific.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "OCR Engine Modes:\n",
    "\n",
    "0   Legacy Engine Only.\n",
    "1   Neural Nets LSTM Engine Only.\n",
    "2   Legacy + LSTM Engines.\n",
    "3   Default, based on what is available.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de7bbf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config=r\"--psm 3 --oem 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f939ee12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\OCR\\\\images'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir=os.getcwd()\n",
    "dir_list=os.listdir(current_dir)\n",
    "images_dir=dir_list[1]\n",
    "images_path=current_dir+\"\\\\\"+images_dir\n",
    "images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "799be242",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files_path=current_dir+\"\\\\\"+\"tesseract_output\"\n",
    "for image in os.listdir(images_path):\n",
    "    image_path=images_path+\"\\\\\"+image\n",
    "    text_file_name=text_files_path+\"\\\\\"+image.split(\".\")[0]+\".txt\"\n",
    "    text_file=open(text_file_name,\"w\")\n",
    "    text_file.write(pytesseract.image_to_string(PIL.Image.open(image_path),config=config))\n",
    "    text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b2ab5df386526388074a24f52977a4b5949b6ec9e2402ce0c4cf1ae4c150783"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
